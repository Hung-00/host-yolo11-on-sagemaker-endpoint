{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "33dcbabf-2c40-4c28-bf1c-daf9ffef3ca3",
      "metadata": {
        "tags": []
      },
      "source": [
        "## 1. Import Python Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "663dc165-7f93-42b0-ad01-f1651650d1b7",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os, sagemaker, subprocess, boto3, time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4183a04e-2ab1-4b76-9fdb-4a55b6db923d",
      "metadata": {
        "tags": []
      },
      "source": [
        "## 2. (OPTIONAL) Download Images from S3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e620a18-a513-4768-a701-0c743603734a",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "bucket_name = \"uniben-data\"\n",
        "prefix = \"yolo-validation/\"\n",
        "local_dir = \"uniben-data/images/val\"\n",
        "\n",
        "if not os.path.isdir(local_dir):\n",
        "    raise FileNotFoundError(f\"Local directory not found: {local_dir}\")\n",
        "        \n",
        "s3 = boto3.client('s3')\n",
        "paginator = s3.get_paginator('list_objects_v2')\n",
        "\n",
        "for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):\n",
        "    for obj in page.get('Contents', []):\n",
        "        key = obj['Key']\n",
        "        if key.endswith('/'):\n",
        "            continue  # Skip Folders\n",
        "        filename   = os.path.basename(key)\n",
        "        local_path = os.path.join(local_dir, filename)\n",
        "        s3.download_file(bucket_name, key, local_path)\n",
        "        print('.', end='')\n",
        "print(\"\\nDone downloading images!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "195fac2c-24a4-4bdb-965d-49c434809b1d",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "def rename_files_remove_prefix(folder_path):\n",
        "    \"\"\"\n",
        "    Rename files by removing everything before '__' in the filename\n",
        "    \n",
        "    Args:\n",
        "        folder_path (str): Path to the folder containing files to rename\n",
        "    \"\"\"\n",
        "    # Get all files in the folder\n",
        "    files = glob.glob(os.path.join(folder_path, \"*__*\"))\n",
        "    \n",
        "    renamed_count = 0\n",
        "    \n",
        "    for file_path in files:\n",
        "        # Get the directory and filename\n",
        "        directory = os.path.dirname(file_path)\n",
        "        old_filename = os.path.basename(file_path)\n",
        "        \n",
        "        # Check if filename contains '__'\n",
        "        if '__' in old_filename:\n",
        "            # Split by '__' and take everything after the first occurrence\n",
        "            new_filename = '__'.join(old_filename.split('__')[1:])\n",
        "            \n",
        "            # Create new file path\n",
        "            new_file_path = os.path.join(directory, new_filename)\n",
        "            \n",
        "            # Rename the file\n",
        "            try:\n",
        "                os.rename(file_path, new_file_path)\n",
        "                print(f\"Renamed: {old_filename} -> {new_filename}\")\n",
        "                renamed_count += 1\n",
        "            except OSError as e:\n",
        "                print(f\"Error renaming {old_filename}: {e}\")\n",
        "    \n",
        "    print(f\"\\nTotal files renamed: {renamed_count}\")\n",
        "\n",
        "\n",
        "folder_path = \"uniben-data/labels/val\"\n",
        "rename_files_remove_prefix(folder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81e3ad16-c7dc-4539-8634-4b92825c7e12",
      "metadata": {
        "tags": []
      },
      "source": [
        "## 3. TRAININGS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac38388",
      "metadata": {
        "tags": []
      },
      "source": [
        "### 3.1. Install Ultralytics for YOLO11 model\n",
        "\n",
        "https://docs.ultralytics.com/models/yolo11/#supported-tasks-and-modes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa890ad6",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip3 install albumentationsx ultralytics\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model_name = 'yolo11x.pt'\n",
        "model = YOLO(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cdc3bb8",
      "metadata": {
        "tags": []
      },
      "source": [
        "### 3.2. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b22ed932-dcfd-4b17-8f6d-144c07ac7f60",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_start_time, a = time.strftime(\"%H:%M:%S\", time.localtime()), time.localtime()\n",
        "print(\"Start time:\", train_start_time)\n",
        "\n",
        "train_attempt=\"180_hung\"\n",
        "model.train(\n",
        "            data=\"uniben-dataset.yaml\",\n",
        "            epochs=180,\n",
        "            patience=0,\n",
        "            imgsz=640,\n",
        "            batch=10,\n",
        "            # augment=True,\n",
        "            # auto_augment=\"randaugment\",\n",
        "            exist_ok=True,\n",
        "            project=\"uniben-trained\",\n",
        "            name=train_attempt,\n",
        "            val=True,\n",
        "            # cache=True,\n",
        "            plots=True\n",
        "           )\n",
        "\n",
        "train_end_time, b = time.strftime(\"%H:%M:%S\", time.localtime()), time.localtime()\n",
        "print(\"End time:\", train_end_time)\n",
        "\n",
        "print(f\"Training Time = {(time.mktime(b) - time.mktime(a))/60:0.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dae1f85d-52c2-4058-98cb-5342d84df25f",
      "metadata": {},
      "source": [
        "### Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9d1be8b-39d3-45f9-a42b-b7f59487963b",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_attempt=\"180_hung\"\n",
        "print(train_attempt)\n",
        "model = YOLO(f'./uniben-trained/{train_attempt}/weights/best.pt')\n",
        "metrics = model.val(\n",
        "            data=\"uniben-dataset.yaml\",\n",
        "            project=\"uniben-val\",\n",
        "            name=train_attempt,\n",
        "            save_json=True,\n",
        "            iou=0.85,\n",
        "            imgsz=640,\n",
        "            batch=10,\n",
        "            plots=True,\n",
        "            save_txt=True,\n",
        "            save_conf=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "282c5bbf-7e41-4eea-a302-368a21df4fc8",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(\"mAP50-95: \", metrics.box.map)  # mAP50-95\n",
        "print(\"mAP50   : \", metrics.box.map50)  # mAP50\n",
        "print(\"mAP75   : \", metrics.box.map75)  # mAP75\n",
        "print(\"mean_results(): Mean of results, returns mp, mr, map50, map   : \", metrics.box.mean_results())  \n",
        "\n",
        "print(\"AP at IoU thresholds from 0.5 to 0.95 for all classes  : \", metrics.box.ap) \n",
        "print(\"mp(): Mean precision of all classes   : \", metrics.box.mp)\n",
        "print(\"mr(): Mean recall of all classes   : \", metrics.box.mr)  \n",
        "\n",
        "print(\"list of mAP50-95 for each category: \", metrics.box.maps)  # list of mAP50-95 for each category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea61f11-2cb4-4937-ac85-f974203dfa67",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(metrics.summary()) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac05a7e9-be68-40f8-abc3-e25d3fbe861f",
      "metadata": {
        "tags": []
      },
      "source": [
        "### 3.3. (OPTIONAL) Resume training from the lastest epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9a414a7-37a1-4673-99e3-d44522e4a862",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Get the latest train folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e289e2c8-1827-4d6c-b6c8-af2692bdfa89",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "runs_dir = \"runs/detect\"\n",
        "train_dirs = [\n",
        "    d for d in os.listdir(runs_dir)\n",
        "    if os.path.isdir(os.path.join(runs_dir, d)) and d.startswith(\"train\")\n",
        "]\n",
        "\n",
        "latest_train_attempt = max(\n",
        "    train_dirs,\n",
        "    key=lambda d: os.path.getmtime(os.path.join(runs_dir, d))\n",
        ")\n",
        "\n",
        "print(\"Latest train folder: \", latest_train_attempt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dffc8ce-0e4a-45c2-bccc-02b0904c7975",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Resume the training process of the latest train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bebb857",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = YOLO(f'runs/detect/{latest_train_attempt}/weights/last.pt')\n",
        "model.train(resume=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afb9a014-c542-4045-80e5-c3968601d63b",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### 3.4. (IMPORTANT, OPTIONAL) Local Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb19be2c-909a-42a6-8833-8d22c05a2900",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "source": [
        "### Get the latest best.pt from latest train, put it into latest-best-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e14ae7eb-cdd4-4d19-8ecf-77f8ff2be7bb",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "runs_dir   = \"runs/detect\"            \n",
        "target_dir = \"latest-best-model\"   \n",
        "\n",
        "candidates = []\n",
        "for name in os.listdir(runs_dir):\n",
        "    path = os.path.join(runs_dir, name)\n",
        "    if os.path.isdir(path) and name.startswith(\"train\"):\n",
        "        candidates.append(path)\n",
        "\n",
        "if not candidates:\n",
        "    raise RuntimeError(f\"No 'train*' subfolders in {runs_dir}\")\n",
        "\n",
        "latest = max(candidates, key=lambda p: os.path.getmtime(p))\n",
        "print(f\"Latest train folder: {latest}\")\n",
        "\n",
        "src = os.path.join(latest, \"weights\", \"best.pt\")\n",
        "dst = os.path.join(target_dir, \"best.pt\")\n",
        "shutil.copy2(src, dst)\n",
        "print(f\"Copied:\\n  {src}\\n→ {dst}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc1e54a8-63dc-42ce-998f-45756f9168c5",
      "metadata": {
        "tags": []
      },
      "source": [
        "### Create local model to invoke"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c96a3a9d-a967-493d-8243-cc8da72df286",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python\n",
        "import cv2, numpy as np, matplotlib.pyplot as plt, random\n",
        "import base64, json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d21a26ec-9aa0-4c32-882e-8a54a795fd06",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_attempt=\"180_hung\"\n",
        "print(train_attempt)\n",
        "model = YOLO(f'./uniben-trained/{train_attempt}/weights/best.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39142f16-ba17-4972-8b4b-c23916aaf908",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "img_path = 'images-test/z6686604803522_8d40b41b8489d82e13f15d9db092d1d8.jpg'\n",
        "result = model.predict(\n",
        "    source=img_path,\n",
        "    save=False,\n",
        ")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cf5ce5a-12a0-4de1-b25f-a72041f08db1",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "orig_image = cv2.imread(img_path)\n",
        "\n",
        "CLASS_COLORS = {\n",
        "    0: (0,255,0),\n",
        "    1: (255,0,0),\n",
        "    2: (0,0,255),\n",
        "    3: (0,0,0),\n",
        "}\n",
        "\n",
        "CLASS_NAMES = {\n",
        "    0: \"abben\",\n",
        "    1: \"boncha\",\n",
        "    2: \"joco\",\n",
        "    3: \"shelf\",\n",
        "}\n",
        "\n",
        "for r in result:  # results is a list\n",
        "    boxes = r.boxes.xyxy.cpu().numpy()\n",
        "    classes = r.boxes.cls.cpu().numpy().astype(int)\n",
        "    for (x1, y1, x2, y2), classID in zip(boxes, classes):\n",
        "        color = CLASS_COLORS.get(classID, (255, 255, 255))\n",
        "        cv2.rectangle(\n",
        "            orig_image,\n",
        "            (int(x1), int(y1)),\n",
        "            (int(x2), int(y2)),\n",
        "            color,\n",
        "            thickness=2\n",
        "        )\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.imshow(cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "out_path = 'output_with_boxes.jpg'\n",
        "cv2.imwrite(out_path, orig_image)\n",
        "print(f\"Annotated image saved to {out_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a919173f-ebe4-47ea-bbb0-74902ccd593e",
      "metadata": {
        "tags": []
      },
      "source": [
        "### Run prediction for all validation images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15f017e4-a380-4c31-b197-dd80819fc2b5",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "folder_path = 'uniben-data/images/val/'\n",
        "all_entries = os.listdir(folder_path)\n",
        "\n",
        "all_images_test = [f for f in all_entries\n",
        "              if os.path.isfile(os.path.join(folder_path, f))]\n",
        "\n",
        "print(all_images_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1d3bc15-f13a-44e4-82aa-3828afe04cd0",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "for img in all_images_test:\n",
        "    img_path = f'uniben-data/images/val/{img}'\n",
        "    result = model.predict(\n",
        "        source=img_path,\n",
        "        save=False,\n",
        "    )\n",
        "\n",
        "    orig_image = cv2.imread(img_path)\n",
        "\n",
        "    CLASS_COLORS = {\n",
        "        0: (0,255,0),\n",
        "        1: (255,0,0),\n",
        "        2: (0,0,255),\n",
        "        3: (0,0,0),\n",
        "    }\n",
        "\n",
        "    for r in result:  # results is a list\n",
        "        boxes = r.boxes.xyxy.cpu().numpy()\n",
        "        classes = r.boxes.cls.cpu().numpy().astype(int)\n",
        "        scores  = r.boxes.conf.cpu().numpy()\n",
        "        for (x1, y1, x2, y2), classID, score in zip(boxes, classes, scores):\n",
        "            color = CLASS_COLORS.get(classID, (255, 255, 255))\n",
        "            cv2.rectangle(\n",
        "                orig_image,\n",
        "                (int(x1), int(y1)),\n",
        "                (int(x2), int(y2)),\n",
        "                color,\n",
        "                thickness=2\n",
        "            )\n",
        "            # Conf score\n",
        "            label = f\"{score:.2f}\"\n",
        "            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
        "            cv2.rectangle(\n",
        "                orig_image,\n",
        "                (int(x1), int(y1) - h - 4),\n",
        "                (int(x1) + w, int(y1)),\n",
        "                color,\n",
        "                cv2.FILLED\n",
        "            )\n",
        "            cv2.putText(\n",
        "                orig_image,\n",
        "                label,\n",
        "                (int(x1), int(y1) - 2),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.5,\n",
        "                (255,255,255),\n",
        "                thickness=1,\n",
        "                lineType=cv2.LINE_AA\n",
        "            )\n",
        "\n",
        "    # plt.figure(figsize=(12,8))\n",
        "    # plt.imshow(cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB))\n",
        "    # plt.axis('off')\n",
        "    # plt.show()\n",
        "\n",
        "    out_path = f'images-test-annotated/{img}'\n",
        "    cv2.imwrite(out_path, orig_image)\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5671b3b9-bf4f-496a-8aaf-47c4ad28c2c9",
      "metadata": {},
      "source": [
        "# -----------------------------\n",
        "# Deploy endpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c4f30e2-4916-457a-9cf5-f24f4944835a",
      "metadata": {
        "tags": []
      },
      "source": [
        "## 4. Zip the code and model into `model.tar.gz` and upload it to specific S3 bucket\n",
        "Here permission is granted to the S3 bucket created with CDK and not any other bucket"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bf6a058-dfe0-4aa5-a791-04c7e6a9b2ab",
      "metadata": {},
      "source": [
        "Vào trong folder train của mô hình muốn deploy, copy best.pt ra ngoài"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b770143-b669-4bef-9f03-7b76d65096b3",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Copy file from source folder to destination folder\n",
        "import shutil\n",
        "train_attempt=\"180_hung\"\n",
        "source_file = f\"uniben-trained/{train_attempt}/weights/best.pt\"\n",
        "destination_folder = \"./\"\n",
        "\n",
        "# Copy the file (preserves metadata)\n",
        "shutil.copy2(source_file, destination_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcbe0653-b31d-4b52-8edf-839eb2efa1e3",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "model_zip = 'best.pt'\n",
        "code_zip = \"code/\"\n",
        "bashCommand = f\"tar -cpzf  model.tar.gz {model_zip} {code_zip}\"\n",
        "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
        "output, error = process.communicate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "720e0244",
      "metadata": {
        "tags": []
      },
      "source": [
        "## 5. Select yolo11 bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ultimate-triangle",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "s3_client = boto3.client('s3')\n",
        "response = s3_client.list_buckets()\n",
        "for bucket in response['Buckets']:\n",
        "    if 'yolo11' in bucket[\"Name\"]:\n",
        "        bucket = 's3://' + bucket[\"Name\"]\n",
        "        break\n",
        "print(f'Bucket: {bucket}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08e5b179",
      "metadata": {
        "tags": []
      },
      "source": [
        "## 6. Upload model to S3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d4c5032-8a51-4539-8ef6-cfa8f07e2d8b",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sagemaker import s3\n",
        "from sagemaker import get_execution_role\n",
        "\n",
        "sm_client = boto3.client(service_name=\"sagemaker\")\n",
        "runtime_sm_client = boto3.client(service_name=\"sagemaker-runtime\")\n",
        "\n",
        "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
        "print(f'Account ID: {account_id}')\n",
        "role = get_execution_role()\n",
        "print(f'Role: {role}')\n",
        "\n",
        "prefix = \"yolo11\"\n",
        "model_data = s3.S3Uploader.upload(\"model.tar.gz\", bucket + \"/\" + prefix)\n",
        "print(f'Model Data: {model_data}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91c395a5",
      "metadata": {
        "tags": []
      },
      "source": [
        "## 7. Create the SageMaker PyTorchModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfdced23-e766-4ead-9a16-7c45dec8c0a6",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sagemaker.pytorch import PyTorchModel\n",
        "\n",
        "sess = sagemaker.Session(default_bucket=bucket.split('s3://')[-1])\n",
        "model = PyTorchModel(entry_point='inference.py',\n",
        "                     model_data=model_data, \n",
        "                     framework_version='1.12', \n",
        "                     py_version='py38',\n",
        "                     role=role,\n",
        "                     env={'TS_MAX_RESPONSE_SIZE':'20000000', 'YOLO11_MODEL': 'best.pt'},\n",
        "                     sagemaker_session=sess)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "polyphonic-outline",
      "metadata": {
        "tags": []
      },
      "source": [
        "## 8. Deploy the model on SageMaker Endpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "694f2ab4-fe8a-4891-8e31-fcd20b1a46e7",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(time.strftime(\"%Y-%m-%d-%H-%M\", time.localtime()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "convinced-miller",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sagemaker.deserializers import JSONDeserializer\n",
        "\n",
        "INSTANCE_TYPE = 'ml.c5.xlarge'\n",
        "ENDPOINT_NAME = 'yolo11-pytorch-' + str(time.strftime(\"%Y-%m-%d-%H-%M\", time.localtime()))\n",
        "print(ENDPOINT_NAME)\n",
        "model.deploy(initial_instance_count=1, \n",
        "             instance_type=INSTANCE_TYPE,\n",
        "             deserializer=JSONDeserializer(),\n",
        "             endpoint_name=ENDPOINT_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "054fb5d4-fd68-45a6-827b-154c17fa5886",
      "metadata": {
        "tags": []
      },
      "source": [
        "## 9.(OPTIONAL) Cleanup by removing Endpoint, Endpoint Config and Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba34a8d7-101d-4a26-9f9e-8c1af4ee4ce8",
      "metadata": {},
      "outputs": [],
      "source": [
        "response = sm_client.describe_endpoint_config(EndpointConfigName=ENDPOINT_NAME)\n",
        "print(response)\n",
        "endpoint_config_name = response['EndpointConfigName']\n",
        "\n",
        "# Delete Endpoint\n",
        "sm_client.delete_endpoint(EndpointName=ENDPOINT_NAME)\n",
        "\n",
        "# Delete Endpoint Configuration\n",
        "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
        "\n",
        "# Delete Model\n",
        "for prod_var in response['ProductionVariants']:\n",
        "    model_name = prod_var['ModelName']\n",
        "    sm_client.delete_model(ModelName=model_name)     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86fae8ca-39ba-48e3-b2db-7d8e08f9a694",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def upload_folder_to_s3(local_folder, bucket_name, s3_folder_prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Upload a local folder to S3 bucket\n",
        "    \n",
        "    Args:\n",
        "        local_folder (str): Path to local folder to upload\n",
        "        bucket_name (str): Name of S3 bucket\n",
        "        s3_folder_prefix (str): Prefix for S3 keys (folder path in bucket)\n",
        "    \"\"\"\n",
        "    \n",
        "    s3_client = boto3.client('s3')\n",
        "    print(1)\n",
        "    # Walk through all files in the local folder\n",
        "    for root, dirs, files in os.walk(local_folder):\n",
        "        for file in files:\n",
        "            local_path = os.path.join(root, file)\n",
        "            \n",
        "            # Calculate relative path from the base folder\n",
        "            relative_path = os.path.relpath(local_path, local_folder)\n",
        "            \n",
        "            # Create S3 key (object name)\n",
        "            if s3_folder_prefix:\n",
        "                s3_key = f\"{s3_folder_prefix}/{relative_path}\".replace(\"\\\\\", \"/\")\n",
        "            else:\n",
        "                s3_key = relative_path.replace(\"\\\\\", \"/\")\n",
        "            \n",
        "            try:\n",
        "                print(f\"Uploading {local_path} to s3://{bucket_name}/{s3_key}\")\n",
        "                s3_client.upload_file(local_path, bucket_name, s3_key)\n",
        "            except Exception as e:\n",
        "                print(f\"Error uploading {local_path}: {e}\")\n",
        "\n",
        "# Example usage\n",
        "upload_folder_to_s3(\n",
        "    local_folder=\"./uniben-data/labels/val\",\n",
        "    bucket_name=\"uniben-data\",\n",
        "    s3_folder_prefix=\"hung_lambda/labels/val\" \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e681c89d-29e4-436f-bd9b-665a0dd87dd5",
      "metadata": {},
      "source": [
        "# TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4993975a-00e3-49bd-b5cd-f0d4762a774c",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# build_and_push.py\n",
        "import boto3\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def get_account_id():\n",
        "    \"\"\"Get AWS account ID\"\"\"\n",
        "    sts = boto3.client('sts')\n",
        "    return sts.get_caller_identity()['Account']\n",
        "\n",
        "def get_region():\n",
        "    \"\"\"Get AWS region\"\"\"\n",
        "    session = boto3.Session()\n",
        "    return session.region_name\n",
        "\n",
        "def create_ecr_repository(repository_name, region):\n",
        "    \"\"\"Create ECR repository if it doesn't exist\"\"\"\n",
        "    ecr = boto3.client('ecr', region_name=region)\n",
        "    \n",
        "    try:\n",
        "        ecr.describe_repositories(repositoryNames=[repository_name])\n",
        "        print(f\"Repository {repository_name} already exists\")\n",
        "    except ecr.exceptions.RepositoryNotFoundException:\n",
        "        ecr.create_repository(repositoryName=repository_name)\n",
        "        print(f\"Created repository {repository_name}\")\n",
        "\n",
        "def build_and_push_docker_image():\n",
        "    \"\"\"Build and push Docker image to ECR\"\"\"\n",
        "    \n",
        "    # Configuration\n",
        "    account_id = get_account_id()\n",
        "    region = get_region()\n",
        "    repository_name = \"yolo11-training\"\n",
        "    image_tag = \"latest\"\n",
        "    \n",
        "    # Full image URI\n",
        "    image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{repository_name}:{image_tag}\"\n",
        "    \n",
        "    print(f\"Account ID: {account_id}\")\n",
        "    print(f\"Region: {region}\")\n",
        "    print(f\"Repository: {repository_name}\")\n",
        "    print(f\"Image URI: {image_uri}\")\n",
        "    \n",
        "    # Create ECR repository\n",
        "    create_ecr_repository(repository_name, region)\n",
        "    \n",
        "    # Get ECR login token\n",
        "    print(\"Getting ECR login token...\")\n",
        "    ecr = boto3.client('ecr', region_name=region)\n",
        "    auth_token = ecr.get_authorization_token()['authorizationData'][0]['authorizationToken']\n",
        "    \n",
        "    # Login to ECR\n",
        "    print(\"Logging in to ECR...\")\n",
        "    login_cmd = f\"aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin {account_id}.dkr.ecr.{region}.amazonaws.com\"\n",
        "    subprocess.run(login_cmd, shell=True, check=True)\n",
        "    \n",
        "    # Build Docker image\n",
        "    print(\"Building Docker image...\")\n",
        "    build_cmd = f\"docker build -t {repository_name} .\"\n",
        "    subprocess.run(build_cmd, shell=True, check=True)\n",
        "    \n",
        "    # Tag the image\n",
        "    print(\"Tagging image...\")\n",
        "    tag_cmd = f\"docker tag {repository_name}:latest {image_uri}\"\n",
        "    subprocess.run(tag_cmd, shell=True, check=True)\n",
        "    \n",
        "    # Push to ECR\n",
        "    print(\"Pushing image to ECR...\")\n",
        "    push_cmd = f\"docker push {image_uri}\"\n",
        "    subprocess.run(push_cmd, shell=True, check=True)\n",
        "    \n",
        "    print(f\"\\nDocker image pushed successfully!\")\n",
        "    print(f\"Image URI: {image_uri}\")\n",
        "    \n",
        "    return image_uri\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure we're in the right directory\n",
        "    if not os.path.exists(\"Dockerfile\"):\n",
        "        print(\"Error: Dockerfile not found in current directory\")\n",
        "        print(\"Please run this script from the directory containing the Dockerfile\")\n",
        "        sys.exit(1)\n",
        "    \n",
        "    image_uri = build_and_push_docker_image()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "412e5842",
      "metadata": {},
      "outputs": [],
      "source": [
        "docker build -t yolo ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffeebc3a-86f8-43bf-9e78-f95ed44cac5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "cp -r ./uniben-data/images/train/* local_test/input/data/train/images/\n",
        "cp -r ./uniben-data/labels/train/* local_test/input/data/train/labels/\n",
        "cp -r ./uniben-data/images/val/* local_test/input/data/validation/images/\n",
        "cp -r ./uniben-data/labels/val/* local_test/input/data/validation/labels/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17ff700b-3177-4488-837c-e9bbad9048bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "docker run --rm -it \\\n",
        "  --gpus all \\\n",
        "  -v $(pwd)/local_test/input/data:/opt/ml/input/data \\\n",
        "  -v $(pwd)/local_test/model:/opt/ml/model \\\n",
        "  -v $(pwd)/local_test/output:/opt/ml/output \\\n",
        "  -e SM_MODEL_DIR=/opt/ml/model \\\n",
        "  -e SM_CHANNEL_TRAIN=/opt/ml/input/data/train \\\n",
        "  -e SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation \\\n",
        "  -e SM_OUTPUT_DATA_DIR=/opt/ml/output/data \\\n",
        "  yolo \\\n",
        "  /bin/bash"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_python3",
      "language": "python",
      "name": "conda_python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
